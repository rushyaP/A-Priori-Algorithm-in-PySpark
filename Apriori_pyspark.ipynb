{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoBVndZ1EnHk"
   },
   "source": [
    "***Rushya Puttam***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FpynhJr6qxO"
   },
   "source": [
    "**Installing PySpark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8WJioR1OX43b",
    "outputId": "b6e297cf-a0f5-431a-da8d-0f8976a5dd29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nChqzvR6x9X"
   },
   "source": [
    "**Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIonfG2oYDeh"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import sys\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0QIobWuYHqJ"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_qTSPNK65RW"
   },
   "source": [
    "**Initiating Spark Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLNb6sWwbJ2h"
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\",\"Project 1 Apriori Algorithm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YloZcQXA8COQ"
   },
   "source": [
    "**Reading Input file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWfawT8Fb3zh"
   },
   "outputs": [],
   "source": [
    "input='/content/drive/My Drive/browsing.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StDp3thLb6G5"
   },
   "outputs": [],
   "source": [
    "inputRDD=sc.textFile(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8KCc_448Hpj"
   },
   "source": [
    "**Setting support to 85**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-oV4-6icJC_"
   },
   "outputs": [],
   "source": [
    "s=85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLs7A0pv8M_u"
   },
   "source": [
    "**Modifying the given input. Removing the trailing spaces for each line in input and converting to frozensets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OVq4RI-b79p"
   },
   "outputs": [],
   "source": [
    "def modify_input(rdditem):\n",
    "  rdditem=rdditem.strip()\n",
    "  rdditem=rdditem.split()\n",
    "  rdditem=frozenset(rdditem)\n",
    "  return rdditem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgK2yeBeb-Rv"
   },
   "outputs": [],
   "source": [
    "#This gives frozenset for each line in the input as map is used\n",
    "intermediate_input=inputRDD.map(lambda x:modify_input(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nttHmAlScABi"
   },
   "outputs": [],
   "source": [
    "#This gives each item separetly in the input file as flatmap is used. Also converting to frozenset\n",
    "modified_input=inputRDD.flatMap(lambda x:modify_input(x)).map(lambda x :frozenset((x,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9wDHpdC-EW5"
   },
   "source": [
    "**Generating singletons(singletons with their whole count and the singletons with count >=s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahf0Q9N6cC6G"
   },
   "outputs": [],
   "source": [
    "#Generating Candidate Singletons\n",
    "candidate_singletons=modified_input.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BD76wdymcLGl"
   },
   "outputs": [],
   "source": [
    "#Generating Frequent Singletons\n",
    "freq_singletons=candidate_singletons.filter(lambda x:x[1]>=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9UHdcoZ-fh1"
   },
   "source": [
    "**Recursive for loop to generate 2-freq itemsets, 3-freq itemsets and 4-freq itemsets from 1-freq itemsets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6YWhuezOtEp"
   },
   "source": [
    "***Broadcasted the singletons and generating combinations for every line in input if the prev freq tems are a subset of each line in input***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lzWKLIucONx"
   },
   "outputs": [],
   "source": [
    "def get_freqitems(freq_items,k):\n",
    "  freq_combikeys=freq_items.map(lambda x:x[0])\n",
    "  freq_combi_bd=sc.broadcast(freq_combikeys.collect())\n",
    "  def get_combi(rdd):\n",
    "      if len(rdd)>k-1: \n",
    "        for i in freq_combi_bd.value:\n",
    "          if i.issubset(rdd):\n",
    "            return tuple(itertools.combinations(rdd,k))\n",
    "      return \"\"\n",
    "  next_combi=intermediate_input.flatMap(get_combi) \n",
    "  candidate_itemsets=next_combi.map(lambda x:frozenset(x)).map(lambda x:(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "  frequent_itemsets=candidate_itemsets.filter(lambda x:x[1]>s)\n",
    "  if (k<4):\n",
    "    temp=frequent_itemsets\n",
    "    #print(temp.take(2))\n",
    "    frequent_itemsets=get_freqitems(frequent_itemsets,k+1)\n",
    "    #print(frequent_itemsets.take(2))\n",
    "    return temp.union(frequent_itemsets)\n",
    "  return frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LK4JUNxJ_SJP"
   },
   "source": [
    "**Calling recursive for loop to generate 2,3,4- Freq items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwtLAJUXcTu1"
   },
   "outputs": [],
   "source": [
    "Freq_itemsets_234=get_freqitems(freq_singletons,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0sHER8oCK7X"
   },
   "source": [
    "**Generating Association Rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4OxuiOVcVUc"
   },
   "outputs": [],
   "source": [
    "#Keeping only 1,2,3 freq itemsets since 4-freq items never comes to denominator while geenrating association rules\n",
    "Freq_itemsets_123=freq_singletons+Freq_itemsets_234.filter(lambda x:len(x[0])<4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBK2zEMtcf3V"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary for 1,2,3 Freq itemsets and broadcasting the dictionary\n",
    "Freq_itemsets_123_dict = {i[0] : i[1] for i in Freq_itemsets_123.collect()}\n",
    "Freq_itemsets_123_dictbd=sc.broadcast(Freq_itemsets_123_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dovIKmfuDwnx"
   },
   "source": [
    "**Setting the confidence to 90%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFG0zbkDcyam"
   },
   "outputs": [],
   "source": [
    "c=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8THpZNdecjtU"
   },
   "outputs": [],
   "source": [
    "def assocrules_generation(rdditem):\n",
    "  num = rdditem[1]\n",
    "  length = len(rdditem[0])\n",
    "  comb = itertools.combinations(rdditem[0],length - 1)\n",
    "  lst = []\n",
    "  for i in comb:\n",
    "    denom = Freq_itemsets_123_dictbd.value[frozenset((i))]\n",
    "    confidence = (num / denom)*100\n",
    "    if confidence >= c: \n",
    "      #output format\n",
    "      x1 = ''\n",
    "      for j in i:\n",
    "        x1 = x1 + ',' + str(j)\n",
    "      x1 = x1.strip(',')\n",
    "      x2 = rdditem[0] - frozenset(i)\n",
    "      x2 = str([k for k in x2][0])\n",
    "      lst.append( x1 + ' -> ' + x2 + ' ; Confidence = ' + str(round(confidence,2)) + '%')\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHTnCbUXcuri"
   },
   "outputs": [],
   "source": [
    "assoc_rules=Freq_itemsets_234.flatMap(assocrules_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U968aXcWcwum"
   },
   "outputs": [],
   "source": [
    "assoc_rules.saveAsTextFile('/content/drive/My Drive/output')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project1_Submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
